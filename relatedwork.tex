\section{Related Work}
Applications of machine learning in database internals is still the subject of significant debate this year and will continue to be a contentious question for years to come~\cite{btree, kraska2018case, mitzenmacher2018model, ma2018query}. An important question is what problems are amenable to machine learning and AI solutions. We believe that query optimization is one such sub-area. The problems considered are generally hard and orders of magnitude of performance are at stake. In this setting, correctness is not concern as poor learning solutions will lead to slow but not incorrect execution.

\vspace{0.5em}\noindent \textbf{Cost Function Learning: } 
Admittedly, we are not the first to consider ``learning'' in the query optimizer and there are a number of alternative architectures that one may consider. The precursors to this work are attempts to correct query optimizers through execution feedback.
One of the seminal works in this area is the LEO optimizer~\cite{markl2003leo}. This optimizer uses feedback from the execution of queries to correct inaccuracies in its cost model. The underlying cost model is based on histograms. The basic idea inspired several other important works such as~\cite{chaudhuri2008pay}. The sentiment in this research still holds true today; when Leis et al. extensively evaluated the efficacy of different query optimization strategies they noted that feedback and cost estimation errors are still challenges in query optimizers~\cite{leis2015good}. A natural first place to include machine learning would be what we call \emph{Cost Function Learning}, where statistical learning techniques are used to correct or replace existing cost models. This is very related to the problem of performance estimation of queries~\cite{akdere2012learning, wu2013predicting, wu2013towards}. 

We actually started with this model, where a neural network learns to predict the selectivity of a single relation predicate. Results were successful, albeit very expensive from a data perspective. To estimate selectivity on an attribute with 10k distinct values, the training sets had to include 1000 queries. This architecture suffers from the problem of \emph{featurization of literals}; the results are heavily dependent on learning structure in literal values from the database that are not always straightforward to featurize. This can be especially challenging for string or other non-numerical data types.  A recent workshop does show some promising results in using Deep RL to construct a good feature representation of subqueries but it still requires $>$ 10k queries to train~\cite{ortiz2018learning}. 

\vspace{0.5em}\noindent \textbf{Adaptive Query Optimization}
Adaptive query processing is another line of work that we might think is relevant to the discussion~\cite{avnur2000eddies,deshpande2007adaptive} and the related techniques to re-optimize queries during execution~\cite{markl2004robust, babu2005proactive}. Reinforcement Learning studies sequential problems and adaptive query optimization is naturally a sequential decision problem.
We focus our study on optimization in fixed databases and the adaptivity that we offer is at a workload level. Continuously updating a neural network can be challenging for very fine-grained adaptivity for processing different tuples in different ways. 

\vspace{0.5em}\noindent \textbf{Join Optimization At Scale} 
Scaling up join optimization has been an important problem for several decades, most recently~\cite{neumann2018adaptive}. 
At scale, there are several different approaches that can be used.
There is a long history of randomized algorithms (like the QuickPick algorithm~\cite{waas2000join}) and genetic algorithms~\cite{bennett1991genetic, steinbrunn1997heuristic}.
These algorithms are very pragmatic and it is often the case that commercial optimizers will leverage one of these methods after the number of tables grows beyond a certain point.
The challenge with these methods is that their efficacy is hard to judge.
We found that QuickPick often varied in performance on the same query quite dramatically.

Another heuristic approach is relaxation, or solve the problem exactly under simplified assumptions.
One straight-forward approach is to simply consider greedy search avoiding cartesian products~\cite{fegaras1998new}.
This is also the premise of the IK-KBZ algorithms~\cite{ibaraki1984optimal,krishnamurthy1986optimization}.
Similar linearization arguments were also made in recent work~\cite{trummer2017solving,neumann2018adaptive}.
Experimentally, we found that linearization makes a lot of sense for cost models that resemble those in main-memory database.
Non-linearities arise when there are paging effects and re-use or materialization of results that have to fit in memory.
This was a setting that we found that the relaxations failed to capture accurately.













 


