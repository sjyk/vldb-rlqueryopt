\section{Related Work and Alternative Architectures}
Applications of machine learning in database internals is still the subject of significant debate this year and will continue to be a contentious question for years to come~\cite{btree, kraska2018case, mitzenmacher2018model, ma2018query}. An important question is what problems are amenable to machine learning and AI solutions. We believe that query optimization is one such sub-area. The problems considered are generally hard and orders of magnitude of performance are at stake. In this setting, correctness is not concern as poor learning solutions will lead to slow but not incorrect execution.

\subsection{Cost Function Learning} 
Admittedly, we are not the first to consider ``learning'' in the query optimizer and there are a number of alternative architectures that one may consider. The precursors to this work are attempts to correct query optimizers through execution feedback.
One of the seminal works in this area is the LEO optimizer~\cite{markl2003leo}. This optimizer uses feedback from the execution of queries to correct inaccuracies in its cost model. The underlying cost model is based on histograms. The basic idea inspired several other important works such as~\cite{chaudhuri2008pay}. The sentiment in this research still holds true today; when Leis et al. extensively evaluated the efficacy of different query optimization strategies they noted that feedback and cost estimation errors are still challenges in query optimizers~\cite{leis2015good}. A natural first place to include machine learning would be what we call \emph{Cost Function Learning}, where statistical learning techniques are used to correct or replace existing cost models. This is very related to the problem of performance estimation of queries~\cite{akdere2012learning, wu2013predicting, wu2013towards}. 

We actually started with this model, where a neural network learns to predict the selectivity of a single relation predicate. Results were successful, albeit very expensive from a data perspective. To estimate selectivity on an attribute with 10k distinct values, the training sets had to include 1000 queries. This architecture suffers from the problem of \emph{featurization of literals}; the results are heavily dependent on learning structure in literal values from the database that are not always straightforward to featurize. This can be especially challenging for string or other non-numerical data types.  A recent workshop does show some promising results in using Deep RL to construct a good feature representation of subqueries but it still requires $>$ 10k queries to train~\cite{ortiz2018learning}. 

\subsection{Adaptive Query Optimization}
Adaptive query processing is another line of work that we might think is relevant to the discussion~\cite{avnur2000eddies,deshpande2007adaptive} and the related techniques to re-optimize queries during execution~\cite{markl2004robust, babu2005proactive}. Reinforcement Learning studies sequential problems and adaptive query optimization is naturally a sequential decision problem.
We focus our study on optimization in fixed databases and the adaptivity that we offer is at a workload level. Continuously updating a neural network can be challenging for very fine-grained adaptivity for processing different tuples in different ways. 

\subsection{Join Optimization At Scale} 
Scaling up join optimization has been an important problem for several decades, most recently~\cite{neumann2018adaptive}. 

\textbf{TODO}







 


